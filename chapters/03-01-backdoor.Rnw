\section{Controlando confundidores (critério \textit{backdoor})}
\label{sec:backdoor}

Um confundidor é uma causa comum, 
direta ou indireta, de $X$ em $Y$.
Na existência de confundidores,
a regressão de $Y$ em $X$ no modelo observacional, 
$\E[Y|X]$, é diferente desta regressão
no modelo de intervenção, $\E[Y|do(X)]$.
Isto ocorre pois, quando calculamos $\E[Y|X]$,
utilizamos toda a informação em $X$ para prever $Y$.
Esta informação inclui não apenas 
o efeito causal de $X$ em $Y$, como 
também a informação que $X$ traz indiretamente sobre $Y$ 
pelo fato de ambas estarem associados aos seus confundidores.

Para ilustrar este raciocínio, 
podemos revisitar o \cref{ex:simpson_fim}.
uma vez que Sexo (Z) é causa comum do Tratamento (X) e
da Cura (Y), Z é um confundidor.
Quando calculamos $f(y|x)$ (\cref{eq:prob_causa_1}), 
utilizamos não só o efeito direto de $X$ em $Y$, 
expresso em $f(y|x,z)$, como também 
a informação que indireta que $X$ traz sobre $Y$
por meio do confundidor $Z$,
expressa pela combinação de $f(z|x)$ com $f(y|x,z)$.

Esta seção desenvolve uma estratégia para
medir o efeito causal chamada de 
critério \textit{backdoor}, que
consiste em bloquear 
todos os caminhos de informação que passam por confundidores:

\begin{definition}
 \label{def:backdoor}
 Seja $\sG = (\sV, \sE)$ um grafo causal e $X, Y \in \sV$.
 Dizemos que $\Z \subseteq \sV - \{X,Y\}$ satisfaz 
 o critério ``backdoor'' se:
 \begin{itemize}
  \item $X \notin Anc(\Z)$,
  \item Para todo caminho de $X$ em $Y$, 
  $C = (X, C_2, \ldots, C_{n-1}, Y)$ tal que
  $(C_2, X) \in \sE$, $C$ está bloqueado dado $\Z$.
 \end{itemize}
\end{definition}

\begin{example}
 No \cref{ex:simpson_fim} o único caminho de $X$ em $Y$ em que
 o vértice ligado a $X$ é pai de $X$ é $X \leftarrow Z \rightarrow Y$.
 Como $Z$ é um confudidor neste caminho, ele o bloqueia.
 Assim, $Z$ satisfaz o critério backdoor.
\end{example}

\begin{example}
 <<backdoor_ex_1, fig.pos="t", fig.height=2.5, fig.width=4, fig.cap="Para medir o efeito causal de X em Y, podemos aplicar o critério backdoor. Neste grafo o único caminho aplicável ao critério backdoor é (X, Z, W, Y). Neste caminho, $Z$ é uma cadeia e $W$ é um confundidor. Assim, todas as possibilidades dentre Z, W, (Z,W) bloqueiam o caminho e satisfazem o critério backdoor.", fig.align="center", echo = FALSE, message = FALSE, warning = FALSE>>==
library(dagitty)
library(ggdag)
library(ggplot2)

# Especificar o grafo
grafo <- dagitty("dag {
    X[e] Y[o]
    W -> { Z Y };
    Z -> X;
    X -> { A Y };
    A -> Y
}")
coordinates(grafo) <- list( 
  x=c(W=2, Z=0, X=0, Y=2, A= 1),
  y=c(W=1, Z=1, X=0, Y=0, A= -1))

# Exibir a figura do grafo
ggdag(grafo, layout = "circle") +
  theme(axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank()) +
  xlab("") + ylab("")
@

 Considere o grafo causal na \cref{fig:backdoor_ex_1}.
 Para aplicar o critério backdoor, devemos identificar
 todos os caminhos de $X$ em $Y$ em que
 o vértice ligado a $X$ é pai de $X$, isto é,
 temos $X \leftarrow$. O único caminho deste tipo é:
 $X \leftarrow Z \leftarrow W \rightarrow Y$.
 Neste caminho, $Z$ é uma cadeia e $W$ é um confudidor.
 Assim, é possível bloquear este caminho condicionando
 em $Z$, em $W$, e em $(Z,W)$.
 Isto é, todos estas combinações 
 satisfazem o critério backdoor.
\end{example}

\begin{example}
 <<backdoor_ex_2, fig.pos="t", fig.height=3, fig.width=4, fig.cap="Para medir o efeito causal de X em Y, podemos aplicar o critério backdoor. Neste grafo existem dois caminhos aplicáveis ao critério backdoor: (X, A, B, Y) e (X, C, Y). No primeiro, A é um confundidor. No segundo caminho, C é um confudidor. Assim, (A,C) bloqueia ambos os caminhos e satisfaz o critério backdoor.", fig.align="center", echo = FALSE, message = FALSE, warning = FALSE>>==
library(dagitty)
library(ggdag)
library(ggplot2)

# Especificar o grafo
grafo <- dagitty("dag {
    X[e] Y[o]
    A -> { X B };
    B -> { Y }
    C -> { X Y };
    X -> { D Y };
    D -> Y
}")
coordinates(grafo) <- list( 
  x=c(A=0, B=1, C=2, D=1, X=0, Y=2),
  y=c(A=3, B=2, C=2, D=0, X=1, Y=1))

# Exibir a figura do grafo
ggdag(grafo, layout = "circle") +
  theme(axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank()) +
  xlab("") + ylab("")
@

 Considere o grafo causal na \cref{fig:backdoor_ex_2}.
 Para aplicar o critério backdoor,
 encontramos todos os caminhos de $X$ em $Y$ em que
 o vértice ligado a $X$ é pai de $X$. 
 Há dois caminhos deste tipo:
 $X \leftarrow A \rightarrow B \rightarrow Y$ e
 $X \leftarrow C \rightarrow Y$.
 Como $A$ e $C$ são confudidores, respectivamente,
 no primeiro e segundo caminhos, 
 $(A,C)$ bloqueia ambos eles.
 Assim $(A,C)$ satisfaz o critério backdoor.
 Você consegue encontrar outro conjunto de variáveis que
 satisfaz o critério backdoor?
 
 Também é possível identificar 
 os conjuntos de variáveis que satisfazem
 o critério backdoor por meio
 do pacote \textit{dagitty},
 como ilustrado a seguir:
 
<<backdoor_ex_2_2, message = FALSE, warning = FALSE>>==
library(dagitty)
# Especificar o grafo
grafo <- dagitty("dag{
    X[e] Y[o]
    A -> { X B }; B -> { Y }; C -> { X Y };
    X -> { D Y }; D -> Y }")

adjustmentSets(grafo, type = "all")
@
\end{example}

O critério backdoor generaliza duas condições especiais que
são muito utilizadas.
Em uma primeira condição, 
o valor de $X$ é gerado integralmente por
um aleatorizador, independente de todas as demais variáveis.
Esta ideia é captada pela 
\cref{def:aleatorizacao}, abaixo:

\begin{definition}
 \label{def:aleatorizacao}
 Dizemos que $X$ é um experimento aleatorizado simples 
 se $X$ é ancestral.
\end{definition}

Em um experimento aleatorizado simples não há confundidores.
Assim, $\emptyset$ satisfaz o critério backdoor:

\begin{lemma}
 \label{lemma:backdoor_random}
 Se $X$ é um experimento aleatorizado simples, então
 $\emptyset$ satisfaz o critério backdoor.
\end{lemma}

Veremos que em um experimento aleatorizado simples a
distribuição intervencional é igual 
à distribuição observacional.
Assim, $\E[Y|do(X)] = \E[Y|X]$ e
a inferência causal é reduzida 
à inferência comumente usadas para
a distribuição observacional.

Além disso, o conjunto de todos os pais de $X$
também satisfaz o critério backdoor:

\begin{lemma}
 \label{lemma:backdoor_pais}
 $\Z = Pa(X)$ satisfaz o critério backdoor para
 medir o efeito causal de $X$ em $Y$.
\end{lemma}

A seguir, veremos como o critério backdoor permite
a identificação causal, isto é,
uma equivalência entre quantidades de interesse
obtidas pelo modelo de intervenção e
quantidades obtidas pelo modelo observacional.

\subsection{Identificação causal usando o critério backdoor}

A seguir, o \cref{thm:backdoor} mostra que,
se $\Z$ satisfaz o critério backdoor, então
é possível ligar algumas 
distribuições sob intervenção em $X$ a
distribuições observacionais:

\begin{theorem}
 \label{thm:backdoor}
 Se $\Z$ satisfaz 
 o critério backdoor para medir
 o efeito causal de $X$ em $Y$, então
 \begin{align*}
  f(\z|do(x)) 
  &= f(\z), \text{ e } \\
  f(y|do(x), \z) 
  &= f(y|x, \z).
 \end{align*}
\end{theorem}

O \cref{thm:backdoor} mostra que,
se $\Z$ satisfaz o critério backdoor, então
distribuição de $\Z$ quando
aplicamos uma intervenção em $X$ é igual
à distribuição marginal de $\Z$.
Além disso, a distribuição condicional de
$Y$ dado $\Z$ quando aplicamos uma intervenção em $X$ é igual 
à distribuição de $Y$ dado $X$ e $Z$.
Assim, o \cref{thm:backdoor} relaciona
distribuições que não geraram os dados a 
distribuições que os geraram.
Com base neste resultado, é possível determinar
$f(y|do(x))$ a partir de $f(y,x,\z)$:

\begin{corollary}
 \label{cor:backdoor}
 Se $\Z$ satisfaz 
 o critério backdoor para medir
 o efeito causal de $X$ em $Y$, então
 \begin{align*}
  f(y|do(x)) &=
  \int f(y|x,\z)f(\z)d\z.
 \end{align*}
\end{corollary}

Para compreender intuitivamente o \cref{cor:backdoor},
podemos retornar ao \cref{ex:simpson_fim}.
Considere o caso em que $X, Y, Z$ são as indicadoras de que,
respectivamente, o paciente foi submetido ao tratamento,
se curou e, é de sexo masculino.
Similarmente ao \cref{thm:backdoor},
vimos em \cref{ex:simpson_fim} que $f(y|do(x))$ é
a média de $f(y|x,z)$ ponderada por $f(z)$.
Nesta ponderação, utilizamos $f(z)$ 
ao invés de $f(z|x)$ pois $Z$ é um confundidor e,
assim, no modelo intervencional não propagamos
a informação em $X$ por esta variável.
A mesma lógica se aplica 
às variáveis que satisfazem o critério backdoor.

Para calcular quantidades 
como o $\ACE$ (\cref{def:ace}), 
utilizamos $\E[Y|do(X)]$.
Por meio do \cref{thm:backdoor},
é possível obter equivalências entre
$\E[Y|do(X)]$ e esperanças obtidas
no modelo observacional.
Estas equivalências são descritas
nos \cref{thm:backdoor_ajuste,thm:backdoor_ipw}.

\begin{theorem}
 \label{thm:backdoor_ajuste}
 Se $\Z$ satisfaz 
 o critério backdoor para medir
 o efeito causal de $X$ em $Y$, então
 \begin{align*}
  \E[g(Y)|do(X=x),\Z]
  &= \E[g(Y)|X=x,\Z], \text{ e } \\
  \E[g(Y)|do(X=x)] 
  &= \E[\E[g(Y)|X=x,\Z]]
 \end{align*}
\end{theorem}

\begin{theorem}
 \label{thm:backdoor_ipw}
 Se $\Z$ satisfaz 
 o critério backdoor para medir
 o efeito causal de $X$ em $Y$ e
 $X$ é discreto, então
 \begin{align*}
  \E[g(Y)|do(X=x),\Z] 
  &= \frac{\E[g(Y)\I(X=x)|\Z]}{f(x|\Z)}, \text{ e } \\
  \E[g(Y)|do(X=x)]
  &= \E\left[\frac{g(Y)\I(X=x)}{f(x|\Z)}\right]
 \end{align*}
\end{theorem}

A seguir, veremos como os
\cref{thm:backdoor_ajuste,thm:backdoor_ipw} podem
ser usados para estimar o efeito causal.
Para provar resultados sobre os estimadores obtidos,
a seguinte definição será útil

\begin{definition}
 \label{def:perm}
 Seja $\hat{g}$ um estimador treinado com
 os dados $(\sV_1,\ldots,\sV_n)$.
 Dizemos que $\hat{g}$ é 
 invariante a permutações se
 o estimador não depende da ordem dos dados.
 Isto é, para qualquer permutações dos índices,
 $\pi: \{1,\ldots,n\} \rightarrow \{1,\ldots,n\}$,
 $\hat{g}(\sV_1,\ldots,\sV_n) \equiv 
 \hat{g}(\sV_{\pi(1)},\ldots,\sV_{\pi(n)})$
\end{definition}

\begin{example}
 \label{ex:perm}
 A média amostral é invariante a permutações pois,
 para qualquer permutação $\pi$,
 \begin{align*}
  \frac{\sum_{i=1}^n X_i}{n} 
  = \frac{\sum_{i=1}^n X_{\pi(i)}}{n}.
 \end{align*} 
\end{example}

\subsection{Estimação usando o critério backdoor}
\label{sec:backdoor_est}

\subsubsection{Fórmula do ajuste}

O \cref{thm:backdoor_ajuste} determina que, 
se $\Z$ satisfaz o critério backdoor, então
$\E[Y|do(X),\Z] = \E[Y|X,\Z]$.
Como $\mu(X,Z) := \E[Y|X,\Z]$ é 
a função de regressão de $Y$ em $X$ e $Z$,
podemos estimar $\mu$ utilizando 
quaisquer métodos de estimação para regressão.
Por exemplo, se $Y$ é contínua,
possíveis métodos são:
regressão linear, Nadaraya-Watson, 
floresta aleatória de regressão, redes neurais, \ldots
Por outro lado, se $Y$ é discreta,
então a função de regressão é estimada por
métodos de classificação como:
regressão logística, k-NN, 
floresta aleatória de classificação,
redes neurais, \ldots
Para qualquer opção escolhida,
denotamos o estimador de $\mu$ por $\hmu$.

Utilizando $\hmu$, podemos estimar
$\CACE(\Z)$ diretamente.
Para tal, note que $\CACE(\Z)$ é
função de $\E[Y|do(X),\Z]$.
Como o \cref{thm:backdoor_ajuste} garante que
$\E[Y|do(X=x),\Z] = \mu(x,\Z)$,
podemos definir o estimador
$\hdoyz := \hmu(x,\Z)$.

O \cref{thm:backdoor_ajuste} também 
orienta a estimação do $\ACE$. 
Similarmente ao caso anterior,
o $\ACE$ é função de $\E[Y|do(X)]$.
Pelo \cref{thm:backdoor_ajuste},
$\E[Y|do(X=x)] = \E[\mu(x,\Z)]$.
Assim, se $\hmu \approx \mu$,
$\E[Y|do(X=x)] \approx \E[\hmu(x,\Z)]$.
Como $\E[\hmu(x,\Z)]$ é simplesmente 
uma média populacional,
podemos estimá-la com base
na média amostral:
\begin{align*}
 \hdoy := \frac{\sum_{i=1}^n \hmu(x,\Z_i)}{n} \approx \E[\hmu(x,\Z)]
\end{align*}

\begin{definition}
 \label{def:ajuste}
 Considere que $\Z$ satisfaz o critério backdoor para
 medir o efeito causal de $X$ em $Y$ e
 $\hmu(x,\z)$ é uma estimativa 
 da regressão $\E[Y|X=x,\Z=\z]$.
 Os estimadores de 
 $\E[Y|do(X=x),\Z]$ e
 $\E[Y|do(X=x)]$ pela
 fórmula do ajuste são:
\begin{align*}
 \hdoyz &:= \hmu(x,\Z) \\
 \hdoy &:= \frac{\sum_{i=1}^n \hmu(x,\Z_i)}{n}
\end{align*}
\end{definition}

A seguir mostraremos que,
se $\hmu$ converge para $\mu$, então
$\hdoy$ converge para $\E[Y|do(X=x)]$.
Em outras palavras, é possível utilizar
$\hdoy$ para estimar o efeito causal de $X$ em $Y$
por meio de expressões como o $\ACE$.

\begin{theorem}
 \label{thm:conv_ajuste}
 Seja $\mu(X,\Z) := \E[Y|X,\Z]$.
 Se $\Z$ satisfaz o critério backdoor para
 medir o efeito causal de $X$ em $Y$,
 $\E[|\mu(x,\Z_1)|] < \infty$,
 $\E[|\hmu(x,\Z_1)-\mu(x,\Z_1)|] = o(1)$, 
 e $\hmu$ é invariante a permutações (\cref{def:perm}), então
 $\hdoy \convp \E[Y|do(X=x)]$.
\end{theorem}

A seguir, utilizamos dados simulados para
ilustrar a implementação da fórmula do ajuste.

\begin{example}
 \label{ex:backdoor_est_ajuste}
<<backdoor_est_ex, fig.pos="t", fig.height=2.5, fig.width=4, fig.cap="DAG usado como exemplo para estimar efeito de X em Y.", fig.align="center", echo = FALSE, message = FALSE, warning = FALSE>>==
# Especificar o grafo
grafo <- dagitty("dag {
    X[e] Y[o]
    {A B} -> { X Y }; X -> {C Y}; C -> Y
}")
coordinates(grafo) <- list( 
  x=c(A=0, B=2, X=0, Y=2, C= 1),
  y=c(A=1, B=1, X=0, Y=0, C= -1))

# Exibir a figura do grafo
ggdag(grafo, layout = "circle") +
  theme(axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank()) +
  xlab("") + ylab("")
@

Considere que o grafo causal é
dado pela \cref{fig:backdoor_est_ex}.
Vamos supor que os dados são gerados da seguinte forma:
$\sigma^2 = 0.01$,
$A \sim N(0, \sigma^2)$, 
$B \sim N(0, \sigma^2)$,
$\epsilon \sim Bernoulli(0.95)$
$X \equiv \I(A + B > 0)\epsilon + \I(A + B < 0)(1-\epsilon)$,
$C \sim N(X, \sigma^2)$, e
$Y \sim N(A + B + C + X, \sigma^2)$:

<<backdoor_est_ex_2, message = FALSE, warning = FALSE>>==
# Especificar o grafo
grafo <- dagitty::dagitty("dag {
    X[e] Y[o]
    {A B} -> { X Y }; X -> {C Y}; C -> Y }")

# Simular os dados
n <- 10^5
sd = 0.1
A <- rnorm(n, 0, sd)
B <- rnorm(n, 0, sd)
eps <- rbinom(n, 1, 0.8)
X <- as.numeric(eps*((A + B) > 0) + 
                  (1-eps)*((A + B) <= 0))
C <- rnorm(n, X, sd)
Y <- rnorm(n, A + B + C + X, sd)
data <- dplyr::tibble(A, B, C, X, Y)
@

Estimaremos o efeito causal pela
fórmula do ajuste (\cref{def:ajuste}).
Iniciaremos a análise utilizando $\hmu$ como
sendo uma regressão linear simples:

<<backdoor_est_ex_3>>==
# Sejam Z variáveis que satisfazem o critério backdoor para
# estimar o efeito causal de causa em efeito em grafo.
# Retorna uma fórmula do tipo Y ~ X + Z_1 + ... + Z_d
fm_ajuste <- function(grafo, causa, efeito)
{
  var_backdoor <- dagitty::adjustmentSets(grafo)[[1]]
  regressores = c(causa, var_backdoor)
  fm = paste(regressores, collapse = "+")
  fm = paste(c(efeito, fm), collapse = "~")
  as.formula(fm)
}

# Estima E[Efeito|do(causa = x)] pela 
# formula do ajuste usando mu_chapeu como regressao 
est_do_x_lm <- function(data, mu_chapeu, causa, x)
{
  data %>% 
    dplyr::mutate({{causa}} := x) %>%  
    predict(mu_chapeu, newdata = .) %>% 
    mean()
}

# Estimação do ACE com regressão linear simples
fm <- fm_ajuste(grafo, "X", "Y")
mu_chapeu_lm <- lm(fm, data = data)
ace_ajuste_lm = est_do_x_lm(data, mu_chapeu_lm, "X", 1) - 
  est_do_x_lm(data, mu_chapeu_lm, "X", 0)
round(ace_ajuste_lm)
@

Em alguns casos, não é razoável supor que 
$\E[Y|X,\Z]$ é linear. Nestas situações,
é fácil adaptar o código anterior para
algum método não-paramétrico arbitrário.
Exibimos uma implementação usando XGBoost 
\citep{Chen2023}:

<<backdoor_est_ex_4, message = FALSE, warning = FALSE>>==
library(xgboost)
var_backdoor <- dagitty::adjustmentSets(grafo, "X", "Y")[[1]]
mu_chapeu <- xgboost(
  data = data %>% 
    dplyr::select(all_of(c(var_backdoor, "X"))) %>% 
    as.matrix(),
  label = data %>% 
    dplyr::select(Y) %>% 
    as.matrix(),
  nrounds = 100,
  objective = "reg:squarederror",
  early_stopping_rounds = 3,
  max_depth = 2,
  eta = .25,
  verbose = FALSE
)

est_do_x_xgb <- function(data, mu_chapeu, causa, x)
{
  data %>% 
    dplyr::mutate({{causa}} := x) %>%  
    dplyr::select(c(var_backdoor, causa)) %>% 
    as.matrix() %>% 
    predict(mu_chapeu, newdata = .) %>% 
    mean()
}

ace_est_xgb = est_do_x_xgb(data, mu_chapeu, "X", 1) - 
  est_do_x_xgb(data, mu_chapeu, "X", 0)
round(ace_est_xgb, 2)
@

 Como o modelo linear era adequado para $\E[Y|X,\Z]$,
 não vemos diferença entre a estimativa obtida
 pela regressão linear simples e pelo XGBoost.
 Mas será que as estimativas estão adequadas?
 Como simulamos os dados,
 é possível calcular diretamente $\E[Y|do(X=x)]$:
 \begin{align}
  \label{eq:ex_backdoor_1}
  \E[Y|do(X=x)]
  &= \E[\E[Y|X=x, A, B]]
  & \text{\cref{thm:backdoor_ajuste}} \nonumber \\
  &= \E[\E[\E[Y|X=x, A, B, C]|X=x, A, B]]
  & \text{Lei da esperança total} \nonumber \\
  &= \E[\E[A+B+C+X|X=x, A, B]]
  & Y \sim N(A+B+C+X, \sigma^2) \nonumber \\
  &= \E[A + B + 2x]
  & C \sim N(X, \sigma^2) \nonumber \\
  &= 2x
  & \E[A] = \E[B] = 0
 \end{align}
 Uma vez calculado $\E[Y|do(X=x)]$,
 podemos obter o $\ACE$:
 \begin{align*}
  \ACE
  &= \E[Y|do(X=1)] - \E[Y|do(X=0)] \\
  &= 2 \cdot 1 - 2 \cdot 0 = 2
  & \text{\cref{eq:ex_backdoor_1}}
 \end{align*}
 Portanto, as estimativas do $\ACE$ obtidas 
 pela regressão linear e pelo xgboost 
 estão adequadas.
\end{example}

\subsubsection{Ponderação pelo inverso do escore de propensidade (IPW)}

Uma outra forma de estimar 
$\E[Y|do(X=x)]$ e $\E[Y|do(X=x),\Z]$ é
motivada pelo \cref{thm:backdoor_ipw}.
Este resultado determina que, 
se $\Z$ satisfaz o critério backdoor, então
\begin{align*}
 \E[Y|do(X=x),\Z] 
 &= \frac{\E\left[Y \I(X=x)|\Z\right]}{f(x|\Z)}.
\end{align*}
Na segunda expressão, $\E[Y \I(X=x)|\Z]$ é 
a regressão de $Y\I(X=x)$ em $\Z$.
Assim, esta quantidade pode ser estimada por
um método de regressão arbitrário, que
denotaremos por $\widehat{\E}[Y \I(X=x)|\Z]$.
Também $f(x|\z)$ é 
usualmente chamado de \textit{escore de propensidade}.
Este escore captura a forma como 
os confundidores atuam sobre $X$
nos dados observacionais.
Como $f$ em geral é desconhecido,
$f(x|\z)$ também o é.
Contudo, quando $X$ é discreto,
podemos estimar $f(x|\z)$ utilizando
algum algoritmo arbitrário de classificação.
Denotaremos esta estimativa por $\hf(x|\z)$.
Se a estimativa for boa, temos
\begin{align*}
 \E[Y|do(X=x),\Z]
 &= \frac{\widehat{\E}[Y \I(X=x)|\Z]}{f(x|\Z)}
 \approx \frac{\widehat{\E}[Y \I(X=x)|\Z]}{\hf(x|\z)}.
\end{align*}

O \cref{thm:backdoor_ipw} também orienta
a estimação de $\E[Y|do(X=x)]$.
Se $\Z$ satisfaz o critério backdoor, então
\begin{align*}
 \E[Y|do(X=x)]
 &= \E\left[\frac{Y \I(X=x)}{f(x|\Z)}\right]
\end{align*}
Como nesta expressão a esperança é
uma média populacional,
ela pode ser aproximada pela média amostral
\begin{align*}
 \E\left[\frac{Y \I(X=x)}{f(x|\Z)}\right]
 &\approx n^{-1} \sum_{i=1}^n \frac{Y_i \I(X_i=x)}{\hf(x|\Z_i)}.
\end{align*}

Combinando estas aproximações, obtemos:
\begin{definition}
 \label{def:ipw}
 Considere que $\Z$ satisfaz o critério backdoor para
 medir o efeito causal de $X$ em $Y$ e
 $\hf(x|\z)$ é uma estimativa de $f(x|\z)$.
 Os estimadores de $\E[Y|do(X=x),\Z]$ e $\E[Y|do(X=x)]$ 
 por IPW são:
\begin{align*}
 \hdoyzb &:= \frac{\widehat{\E}[Y \I(X=x)|\Z]}{\hf(x|\z)} \\
 \hdoyb &:= n^{-1} \sum_{i=1}^n \frac{Y_i \I(X_i=x)}{\hf(x|\Z_i)}.
\end{align*}
\end{definition}

Se $\hf$ converge para $f$, então sob 
condições relativamente pouco restritivas
$\hdoyb$ converge para $\E[Y|do(X=x)]$.

\begin{theorem}
 \label{thm:conv_ipw}
 Se $\hf$ é invariante a permutações (\cref{def:perm}),
 $\E[|\hf(x|\Z_1)-f(x|\Z_1)|] = o(1)$, e
 existe $M > 0$ tal que
 $\sup_\z \E[|Y| \I(X=x)|\Z=\z] < M$, e
 existe $\delta > 0$ tal que
 $\inf_z \min\{f(x|\Z_1), \hf(x|\Z_1)\} > \delta$, então
 $\hdoyb \convp \E[Y|do(X=x)]$.
\end{theorem}

A seguir, utilizamos novamente dados simulados para
ilustrar a implementação de IPW:

\begin{example}
\label{ex:backdoor_est_ipw}
Considere que o grafo causal e
o modelo de geração dos dados são 
idênticos àqueles do \cref{ex:backdoor_est_ajuste}.
Iniciaremos a análise utilizando 
regressão logística para estimar $\hf$.
 
 <<backdoor_est_ex_5>>==
# Sejam Z variáveis que satisfazem o critério backdoor para
# estimar o efeito causal de causa em efeito em grafo.
# Retorna uma fórmula do tipo X ~ Z_1 + ... + Z_d
fm_ipw <- function(grafo, causa, efeito)
{
  var_backdoor <- dagitty::adjustmentSets(grafo)[[1]]
  fm = paste(var_backdoor, collapse = "+")
  fm = paste(c(causa, fm), collapse = "~")
  as.formula(fm)
}

# Estimação do ACE por IPW onde
# Supomos X binário e
# f_1 é o vetor P(X_i=1|Z_i)
ACE_ipw <- function(data, causa, efeito, f_1)
{
  data %>% 
  mutate(f_1 = f_1,
         est_1 = {{efeito}}*({{causa}}==1)/f_1,
         est_0 = {{efeito}}*({{causa}}==0)/(1-f_1)
  ) %>% 
  summarise(do_1 = mean(est_1),
            do_0 = mean(est_0)) %>% 
  mutate(ACE = do_1 - do_0) %>% 
  dplyr::select(ACE)
}

fm <- fm_ipw(grafo, "X", "Y")
f_chapeu <- glm(fm, family = "binomial", data = data)
f_1_lm <- predict(f_chapeu, type = "response")
ace_ipw_lm <- data %>% ACE_ipw(X, Y, f_1_lm) %>% as.numeric()
ace_ipw_lm %>% round(2)
@

Também é fácil adaptar o código acima para
estimar $\ACE$ por IPW utilizando
algum método não-paramétrico para estimar $\hf$.
Abaixo há um exemplo utilizando o XGBoost:

 <<backdoor_est_ex_6>>==
var_backdoor <- dagitty::adjustmentSets(grafo)[[1]]
f_chapeu <- xgboost(
  data = data %>% 
    dplyr::select(all_of(var_backdoor)) %>% 
    as.matrix(),
  label = data %>% 
    dplyr::select(X) %>% 
    as.matrix(),
  nrounds = 100,
  objective = "binary:logistic",
  early_stopping_rounds = 3,
  max_depth = 2,
  eta = .25,
  verbose = FALSE
)

covs <- data %>% dplyr::select(all_of(var_backdoor)) %>% as.matrix()
f_1 <- predict(f_chapeu, newdata = covs)
data %>% ACE_ipw(X, Y, f_1) %>% as.numeric() %>% round(2)
@
\end{example}

\subsubsection{Estimador duplamente robusto}

Os \cref{thm:conv_ajuste,thm:conv_ipw} mostram que,
sob suposições diferentes, 
$\hdoy$ e $\hdoyb$ convergem para $\E[Y|do(X=x)]$.
A ideia do estimador duplamente robusto é
combinar ambos os estimadores de forma
a garantir esta convergência sob 
suposições mais fracas.
Para tal, a ideia por trás do 
estimador duplamente é que
este convirja junto a $\hdoy$ 
quando este é consistente e
para $\hdoyb$ quando aquele o é.

\begin{definition}
 Sejam $\Z$ variáveis que satisfazem o critério backdoor
 para medir o efeito causal de $X$ em $Y$ e 
 sejam $\hf$ e $\hmu$ tais quais nas
 \cref{def:ajuste,def:ipw}.
 O estimador duplamente robusto para
 $\E[Y|do(X=x)]$, $\hdoyc$ é tal que
 \label{def:duplo_robusto}
 \begin{align*}
  \hdoyc 
  &= \hdoy + \hdoyb 
  - \sum_{i=1}^n \frac{\I(X_i=x)\hmu(x,\Z_i)}{n\hat{f}(x|\Z_i)}
 \end{align*}
\end{definition}

O estimador duplamente robusto é consistente para
$\E[Y|do(X=x)]$ tanto sob as condições do
\cref{thm:conv_ajuste} quanto sob as do
\cref{thm:conv_ipw}. A ideia básica é que,
sob as condições do \cref{thm:conv_ajuste},
$\hdoy$ é consistente para $\E[Y|do(X=x)]$ e
$\hdoyb - \sum_{i=1}^n \frac{\I(X_i=x)\hmu(x,\Z_i)}{n\hat{f}(x|\Z_i)}$
converge para $0$. Isto é,
quando $\hdoy$ é consistente,
o estimador duplamente robusto seleciona este termo.
Similarmente, sob as condições do \cref{thm:conv_ipw},
$\hdoyb$ é consistente para $\E[Y|do(X=x)]$ e
$\hdoy - \sum_{i=1}^n \frac{\I(X_i=x)\hmu(x,\Z_i)}{n\hat{f}(x|\Z_i)}$
converge para $0$.

\begin{theorem}
 \label{thm:conv_duplo_robusto}
 Suponha que existe $\epsilon > 0$ tal que
 $\inf_\z \hf(x|\z) > \epsilon$,
 existe $M > 0$ tal que 
 $\sup_\z \hmu(x,\z) < M$, e
 $\hmu$ e $\hf$ são invariantes 
 a permutações (\cref{def:perm}).
 Se as condições do \cref{thm:conv_ajuste} ou
 do \cref{thm:conv_ipw} estão satisfeitas, então
 \begin{align*}
  \hdoyc \convp \E[Y|do(X=x)].
 \end{align*}
\end{theorem}

\begin{example}[Estimador duplamente robusto]
\label{ex:backdoor_est_robusto}
Considere que o grafo causal e
o modelo de geração dos dados são iguais
àqueles descritos no \cref{ex:backdoor_est_ajuste}.
Para implementar o estimador duplamente robusto
combinaremos o estimador da fórmula do ajuste obtido 
por regressão linear no \cref{ex:backdoor_est_ajuste} e
aquele de IPW por regressão logística
no \cref{ex:backdoor_est_ipw}.
<<backdoor_est_ex_7>>==
mu_1_lm <- data %>% 
  dplyr::mutate(X = 1) %>%
  predict(mu_chapeu_lm, newdata = .)
mu_0_lm <- data %>% 
  dplyr::mutate(X = 0) %>%
  predict(mu_chapeu_lm, newdata = .)
corr <- data %>% 
  mutate(mu_1 = mu_1_lm, 
         mu_0 = mu_0_lm,
         f_1 = f_1_lm,
         corr_1 = (X == 1)*mu_1/f_1,
         corr_0 = (X == 0)*mu_0/(1-f_1)) %>% 
  summarise(corr_1 = mean(corr_1),
            corr_0 = mean(corr_0)) %>% 
  mutate(corr = corr_1 - corr_0) %>% 
  dplyr::select(corr) %>% 
  as.numeric()
ace_rob_lm <- ace_ajuste_lm + ace_ipw_lm - corr
ace_rob_lm %>% round(2)
@ 
\end{example}

\subsection{Exercícios}

\begin{exercise}
 Prove o \cref{lemma:backdoor_random}.
\end{exercise}

\begin{exercise}
 Prove o \cref{lemma:backdoor_pais}.
\end{exercise}

\begin{exercise}
 Prove que a variância amostral satisfaz
 o \cref{def:perm}.
\end{exercise}

\begin{exercise}
 Utilizando como referência o grafo e
 o código no \cref{ex:backdoor_est_ajuste},
 simule dados tais que a estimativa do $\ACE$ é
 diferente quando um método de regressão linear e
 um de regressão não-paramétrica são usados.
\end{exercise}

\subsection{Regression Discontinuity Design (RDD)}

Em determinadas situações,
$X$ é completamente determinado
pelos confundidores, $\Z$ \citep{Lee2010}.
Por exemplo, considere que 
desejamos determinar o efeito causal que
um determinado programa social do governo traz 
sobre o nível de educação dos cidadãos.
Neste caso, $X$ é a indicadora de que
o indíviduo é elegível ao programa e
$Y$ mede o seu nível de educação.
Em alguns casos, é razoável supor que
$X$ é completamente determinado por $Z$,
a renda do indivíduo.

A situação acima traz desafios para
a fórmula do ajuste e IPW discutidos anteriormente.
Primeiramente, como $X = h(\Z)$, 
não é possível estimar $\E[Y|X=x,\Z=\z]$
quando $x \neq h(\z)$.
Portanto, não é possível utilizar
a fórmula do ajuste, uma vez que
ela se baseia na expressão $\E[\E[Y|X=x,\Z]]$.
Similarmente, o estimador de IPW envolve
uma divisão por $f(x|\Z)$.
Assim, quando $x \neq h(\Z)$
há uma divisão por $0$, 
o que torna o estimador indefinido.

\subsubsection{Identificação causal no RDD}

Apesar destas dificuldades,
é possível medir nestas situações
parte do efeito causal de $X$ em $Y$.
Suponha que $\Z \in \Re$ e que 
existe $z_1$ tal que $X = \I(\Z \geq \z_1)$. 
Por exemplo, um benefício pode estar disponível
apenas para cidadãos que tenham renda 
abaixo de um teto ou
uma lei pode ter efeitos
a partir de uma determinada data.

Neste caso, podemos estar interessados em
$\E[Y|do(X=x),\Z=\z_1]$, 
o efeito causal que $X$ tem na 
fronteira de sua implementação.
Intuitivamente, próximo a esta fronteira,
as unidades amostrais são todas similares 
em relação aos confundidores.
Assim, se na fronteira houver uma diferença em $Y$ entre
os valores de $X$, esta diferença 
deve ser decorrente do efeito causal de $X$.
Esta intuição é formalizada no resultado de
identicação causal abaixo:

\begin{theorem}[\citet{Hahn2001}]
 \label{thm:id_rdd}
 Considere que $\Z \in \Re$ satisfaz o critério backdoor para
 estimar o efeito causal de $X \in \{0,1\}$ em $Y$ e que
 $\E[Y|do(X=0),\Z]$ e $\E[Y|do(X=1),\Z]$ são 
 contínuas em $\Z=\z_1$.
 
 Se $X \equiv \I(\Z \geq \z_1)$, então
 \begin{align*}
  \CACE(\Z=\z_1)
  &= \lim_{\z \downarrow \z_1} \E[Y|\Z = \z] 
  - \lim_{\z \uparrow \z_1} \E[Y|\Z = \z].
 \end{align*}
 
 Se $f(x|\Z) \in (0,1)$ é contínua exceto em $\z_1$, então
 \begin{align*}
  \CACE(\Z=\z_1)
  &= \frac{\lim_{\z \downarrow \z_1} \E[Y|\Z = \z] 
  - \lim_{\z \uparrow \z_1} \E[Y|\Z = \z]}
  {\lim_{\z \downarrow \z_1} f(X=1|\Z=\z) 
  - \lim_{\z \uparrow \z_1} f(X=1|\Z=\z)}.
 \end{align*}
\end{theorem}

Um detalhe sutil do \cref{thm:id_rdd} é que
$X \equiv \I(\Z > \z_1)$ não é
o suficiente para termos certeza que
$\Z$ satisfaz o critério backdoor.
Por exemplo, considere que 
o governo criasse um benefício fiscal para
todas empresas sediadas em um determinado município.
Neste caso, a ocorrência do benefício é
função da sede da empresa. 
Contudo, a relação causal é mais complexa.
Se o benefício for suficientemente alto,
poderia motivar empresas a 
moverem sua sede para o município.
Em outras palavras, 
o benefício seria causa da localização da sede e não o contrário.
Neste caso, não seria possível aplicar o \cref{thm:id_rdd}.
Este tipo de raciocínio indica que a análise por RDD é
mais efetiva quando é difícil interferir sobre o valor de $\Z$.
Por exemplo, como um indivíduo não pode interferir sobre a sua idade,
é mais fácil justificar o uso de RDD em
uma campanha de vacinação em que
apenas indivíduos acima de uma determinada idade são vacinados.

Um outro ponto importante de interpretação do \cref{thm:id_rdd} é que,
embora $\E[Y|do(X=0),\Z]$ e $\E[Y|do(X=1),\Z]$ sejam supostas contínuas,
$f(X=1|\Z)$ e $\E[Y|\Z]$ não o são. Intuitivamente,
podemos imaginar $X$ representa a indicadora de que
uma determinada política é adotada.
Por exemplo, podemos imaginar que $X$ indica que um indivíduo foi vacinado,
$\Z$ a sua idade e $Y$ a sua hospitalização.
Neste caso, $\E[Y|do(X=0),\Z]$ e $\E[Y|do(X=1),\Z]$ representam
a taxa de hospitalização quando
todos os indivíduos são vacinados ou
quando todos eles não o são.
Nestas situações, seria razoável supor que
a taxa de hospitalização é contínua em função da idade, pois
não esperamos que exista uma grande descontinuidade 
nas condições de saúde entre
indivíduos com $69$ e com $70$ anos de idade.
Este tipo de conclusão muitas vezes é resumido pela expressão em latim
\textit{natura non facit saltus}
(a natureza não faz saltos).
Por outro lado, nos dados observados,
a política não é adotada para uma faixa de valores de $\Z$ e
passa a ser adotada a partir de um ponto,
o que é responsável pela descontinuidade em
$\E[Y|\Z]$ e em $f(X=1|\Z)$.
Podemos imaginar que a vacinação é empregada 
somente em indivíduos com mais de $70$ anos.
Esta descontinuidade na política humana cria
uma diferença importante entre indivíduos
com $69$ e com $70$ anos,
o que explica uma diferença grande 
nas taxas de hospitalização entre estas idades
nos dados observados.

\subsubsection{Estimação no RDD}

O \cref{thm:id_rdd} indica que $\CACE(\Z=\z_1)$ é
função da regressão de $Y$ sobre $\Z$, $\E[Y|\Z]$, e
sobre o classificador, $f(X=1|\Z)$.
Uma possível estratégia é estimarmos 
estas quantidades separadamente e, a seguir,
estimarmos o $\CACE$ trocando
as quantias populacionais pelas quantias estimadas.

Uma dificuldade nesta estratégia é que
sabemos que $\E[Y|\Z]$ e $f(X=1|\Z)$ são discontínuas.
Para lidar com esta dificuldade, 
uma possibilidade é 
realizar uma regressão para $\Z < \z_1$ e
outra para $\Z \geq \z_1$.

\begin{definition}
 \label{def:est_rdd}
 Seja $D_{<} = \{i: \Z_i < \z_1\}$
 o conjunto de unidades amostrais em que $\Z_i < \z_1$,
 $\widehat{\E}_{<}[Y|\Z]$ e $\hf_{<}(X=1|\Z)$ regressões ajustadas
 utilizando apenas dados em $D_{<}$ e
 $\widehat{\E}_{\geq}[Y|\Z]$ e $\hf_{\geq}(X=1|\Z)$ ajustadas
 em $D^{c}_{<}$.
 O estimador RDD para $\CACE(\z_1)$ é
 \begin{align*}
  \hCACE(\z_1)
  := \frac{\widehat{\E}_{\geq}[Y|\z_1] - \widehat{\E}_{<}[Y|\z_1]}
  {\hf_{\geq}(X=1|\Z) - \hf_{<}(X=1|\Z)}.
 \end{align*}
 Em particular, se sabemos a priori que
 $f(X=1|\z) = 1$ para $\z \geq \z_1$ e
 $f(X=1|\z) = 0$ para $\z < \z_1$, então
 \begin{align*}
  \hCACE(\z_1)
  := \widehat{\E}_{\geq}[Y|\z_1] - \widehat{\E}_{<}[Y|\z_1]
 \end{align*}
\end{definition}

O exemplo a seguir ilustra a implementação de RDD quando
$X \equiv \I(\Z \geq \z_1)$ utilizando 
tanto regressão linear quanto 
regressão de Kernel de Nadaraya-Watson.

\begin{example}
 \label{ex:rdd}
 Considere que $Z_i$ satisfaz 
 o critério backdoor para estimar 
 o efeito causal de $X$ em $Y$.
 Além disso, $Z_i \sim N(0,1)$,
 $X_i \equiv \I(Z_i \geq 0)$ e
 $Y_i|X_i,Z_i \sim N(50(X_i+1)(Z_i + 1), 1)$.
 Podemos simular os dados da seguinte forma:
 
<<rdd_ex_1_1, fig.pos="t", fig.height=3.5, fig.width=5, fig.cap="Exemplo em que Z satisfaz o critério backdoor para medir o efeito causal de X em Y e X = I(Z > 0). Como resultado da descontinuidade da propensidade de X em Z = 0, há uma descontinuidade na regressão E[Y|Z] no ponto Z=0.", fig.align="center">>==
n <- 1000
Z <- rnorm(n)
X <- Z >= 0
Y <- rnorm(n, 50*(X+1)*(Z+1))
data <- tibble(X, Y, Z)
plot(Z, Y)
@
 
 Como estamos simulando os dados,
 podemos calcular $\CACE(0)$:
 \begin{align*}
  \CACE(0) 
  &= \lim_{\z \downarrow 0}\E[Y|\Z=\z] 
  - \lim_{\z \uparrow 0}\E[Y|\Z=\z]
  & \text{\cref{thm:id_rdd}} \\
  &= \lim_{\z \downarrow 0}\E[Y|X=1,\Z=\z]
  - \lim_{\z \uparrow 0}\E[Y|X=0,\Z=\z] \\
  &= \lim_{\z \downarrow 0} 50(1+1)(\z+1)
  - \lim_{\z \uparrow 0} 50(0+1)(\z+1)
  = 50
 \end{align*}
\end{example}

O código abaixo estima $\CACE(0)$ usando regressão linear:

<<rdd_ex_1_2>>==
regs = data %>% 
  mutate(Z1 = (Z >= 0)) %>% 
  group_by(Z1) %>% 
  summarise(
    intercepto = lm(Y ~ Z)$coefficients[1], 
    coef_angular = lm(Y ~ Z)$coefficients[2]
  ) 
regs

est_cace = 1*regs[2, 2] + 0*regs[2, 3] -
  1*regs[1, 2] + 0*regs[1, 3]
round(as.numeric(est_cace), 2)
@

Similarmente, podemos estimar $\CACE(0)$ usando
regressão por kernel de Nadaraya-Watson:

<<rdd_ex_1_3, warning=FALSE, message=FALSE>>==
library(np)
options(np.messages = FALSE)
nw_reg <- function(data, valor)
{
  bw <- npregbw(xdat = data$Z, ydat = data$Y)$bw
  npksum(txdat= data$Z, exdat = valor, tydat = data$Y, bws = bw)$ksum/
    npksum(txdat = data$Z, exdat = valor, bws = bw)$ksum
}

reg_baixo <- data %>% 
  filter(Z < 0) %>% 
  nw_reg(0)
reg_cima <- data %>% 
  filter(Z >= 0) %>% 
  nw_reg(0)
est_cace <- reg_cima - reg_baixo
round(est_cace, 2)
@

\subsection{Exercícios}

\begin{exercise}
 Crie um exemplo em que,
 ao contrário do \cref{ex:rdd},
 $\E[Y|X=1,\Z]$ não é linear em $\Z$.
 Compare as estimativas de $\CACE$ usando
 a regressão linear e 
 algum método de regressão não-paramétrica.
\end{exercise}
